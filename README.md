# 概要
* anthropicのサンプルをベースにクライアントMCPを作成した
  * Vibe Codingで作成したプロトタイプ用のもののため、実用の際は改修が必要

# 仕様
* anthropicのサンプルでは`node build/index.js path/to/build/index.js`のように、第1引数にローカルMCPサーバーのパスを指定する必要があったが、どのMCPサーバーを使うかもMCPクライアント内でよしなに選択させるようにした
  * LLMを使用（一般的にはプログラムで判定するが、今回プログラムでは精度が悪かったため）
* 1回の質問におけるLLMの呼び出し回数は2回（MCPサーバーの選択と、MCPサーバーを呼び出し他あとの回答の生成）
* 現時点では、必ずTool Useする仕様になっている
* 環境変数は.envに保存

# 使い方
* MCPクライアントのコードをindex.tsに記載
  * 現状`index_gemini_api.ts`が最も良い
* ビルド（index.tsをindex.jsにビルド）
```
npm run build  
```
* MCPクライアントの起動
```
node build/index.js
```
* 2段階のフローで回答する
  * 1. ユーザーは質問を入力する
    * ユーザーの質問をもとに、ローカルに存在する2つのMCPサーバー（アメリカの都市の天気予報と警告を取得するMCPサーバー・Link-AG MCPサーバーをリスト）から適切なMCPサーバーを返答
  * 2. ユーザーは提示されたMCPサーバーの使用で問題なければ「ok」と回答
    * 「ok」の場合、そのMCPサーバーを仕様して回答を生成
    * それ以外の場合、1に戻る
    * LLMを使用

# 使用例
```
ニューヨークの明日の天気は？

ニューヨークの明日の警報は？
```
```
Link-AGの下記の成果を取得し、
①全体の成果数を出力して
②検索対象の発生日時を出力して
③全メディアごとの成果数を表にして（件数が少ないメディアであっても省略しないで全件記載して。表の最終行に「合計数」という行を作って表の件数の合計値を記載して）
・広告ID: 8283, 8294, 8408, 8551, 8552
・発生日時: 2025/7/1
・アウトプット項目: メディアID、メディア名、リファラ、sid
```
https://github.com/user-attachments/assets/cac6e671-d2a7-4bc2-882e-8fcce6dd4648

# ファイルについて
* index_anthropic_api.ts
  * Anthropic APIを使用
  * 1分あたりのレート制限にかかりやすい
* index_gemini_api.ts
  * Gemini APIを使用
* index_gemini_api_through_file.ts（失敗）
  * Gemini APIを使用
  * MCPサーバーのレスポンスをファイルに出力させ、それを読み込んで処理させる →作成されたファイルの読み込み権限がなく回答が正しく返ってこない
* index.ts
  * 実行したいMCPクライアントの処理を貼り付けて実行してください

# 調査結果
## 検証したかったこと
* Claude DesktopではToolのレスポンスが10万文字以上だとコンテキストからカットされてしまうため実用的ではなかった、自作MCPクライアントを使用すればその制限なく、大きなレスポンスデータでも扱えるのか？
  * 例）
    * 2週間分のDMM TVのID/広告ID/リファラ/sidを出力した場合、50万文字（推定80万トークン）
    * 1ヶ月分のDMM TVのID/広告ID/リファラ/sidを出力した場合、88万文字（推定120万トークン）

## 結果
### 結論
* Gemini APIを使用
* コストとレート制限は`Gemini 2.5 Flash-Lite`を使えば許容内で使える可能性がある
* 回答の質に問題あり
  * 元々の課題であった、Toolのレスポンス10万文字制限の問題は突破
  * しかし、その後のLLMの分析がうまくいってないのか結果が正しくない（揺れる、全データを集計していないように見える）
  * Toolのアウトプットを一度ファイルに書き出し、そのファイルを読んでLLMに回答させるようにしたが、ファイルの読み込み権限がLLMになく失敗（index_gemini_api_through_file.ts）

### Anthropic APIを使用した場合
* Toolのレスポンス10万文字制限の問題は突破
* 1分あたりのレート制限にかかってしまう
* sonnet 3.5の場合、レート制限（TPM）: 4万入力トークン/分（キャッシュ除くコンテキストを含めたら20万トークン）

### Gemini APIを使用した場合
* Toolのレスポンス10万文字制限の問題は突破
* レート制限
    * 無料枠は個人Googleアカウント、ビジネスアカウントは有料枠はTier1
    * https://ai.google.dev/gemini-api/docs/rate-limits?hl=ja#tier-1
    * Gemini 2.5 Flash
        * 無料枠のレート制限（TPM）: 25万トークン/分
        * 有料枠のレート制限（TPM）: 100万トークン/分
    * Gemini 2.5 Flash-Lite
        * 無料枠のレート制限（TPM）: 25万トークン/分
        * 有料枠のレート制限（TPM）: 400万トークン/分
    * Gemini 2.0 Flash
        * 無料枠のレート制限（TPM）: 100万トークン/分
        * 有料枠のレート制限（TPM）: 400万トークン/分
    * Gemini 2.0 Flash-Lite
        * 無料枠のレート制限（TPM）: 100万トークン/分
        * 有料枠のレート制限（TPM）: 400万トークン/分
    * **結果: 仮に1ヶ月分のDMM TVのID/広告ID/リファラ/sidを出力した場合、Gemini 2.5 Flash-Lite（有料枠）であれば対応可能。出力項目と件数によるが、1~2ヶ月ほどの量であれば制限内。ただし1分間にデータ量の多い検索を複数回行うのとレート制限にかかる**
* コスト
    * 前提
        * ビジネスアカウント有料枠
        * 入力トークンのみ試算
        * https://ai.google.dev/gemini-api/docs/pricing?hl=ja
    * Gemini 2.5 Flash
        * $0.30/100万トークン
    * Gemini 2.5 Flash-Lite
        * $0.10/100万トークン
    * Gemini 2.0 Flash
        * $0.10/100万トークン
    * Gemini 2.0 Flash-Lite
        * $0.075/100万トークン
    * **結果: 使用頻度が高くなければ問題ない（Gemini 2.5 Flash-Liteを使用したい）。「大量データを取得し複数工程で分析する」ような場合はコスト注意**
* 回答の質
  * Toolのアウトプットは大量データでも成功しているが、その後のLLMの分析がうまくいってないのか結果が正しくない（揺れる、全データを集計していないように見える）
    * 例）直近1日分の件数が正しくは140件だが95件しか分析対象になっていない
    * 例）直近1週間分の件数が正しくは843件だが531件しか分析対象になっていない
    * 例）直近1週間分で質問したところ、MCPサーバのレスポンスは正しい（データの取得はできている）が、その後の回答が空欄で返ってきた
  * 試しに、Toolのアウトプットを一度ファイルに書き出し、そのファイルを読んでLLMに回答させるようにしたが、ファイルの読み込み権限がLLMになく失敗（index_gemini_api_through_file.ts）

# 未対応
* Tool Useしない場合の質問も返答するようにする
* UIを作成したい（Pythonの streamlit）
* 「昨日」の解釈ができない
* MCPの選択から回答まで一貫して行う
* LLMがよしなにMCP複数組み合わせて回答する
